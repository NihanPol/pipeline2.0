1,2c1,15
< import glob, os, os.path, shutil, socket, struct
< import numpy, sys, psr_utils, presto, time
---
> import glob
> import os
> import os.path
> import shutil
> import socket
> import struct
> import sys
> import time
> import subprocess
> import re
> import types
> 
> import numpy as np
> import psr_utils
> import presto
3a17
> import psrfits
5,6c19,38
< # get configurations from config file
< from PALFA_config import *
---
> # Tunable parameters for searching and folding
> # (you probably don't need to tune any of them)
> datatype_flag           = "-psrfits" # PRESTO flag to determine data type
> rfifind_chunk_time      = 2**15 * 0.000064  # ~2.1 sec for dt = 64us
> singlepulse_threshold   = 5.0  # threshold SNR for candidate determination
> singlepulse_plot_SNR    = 6.0  # threshold SNR for singlepulse plot
> singlepulse_maxwidth    = 0.1  # max pulse width in seconds
> to_prepfold_sigma       = 6.0  # incoherent sum significance to fold candidates
> max_cands_to_fold       = 50   # Never fold more than this many candidates
> numhits_to_fold         = 2    # Number of DMs with a detection needed to fold
> low_DM_cutoff           = 2.0  # Lowest DM to consider as a "real" pulsar
> lo_accel_numharm        = 16   # max harmonics
> lo_accel_sigma          = 2.0  # threshold gaussian significance
> lo_accel_zmax           = 0    # bins
> lo_accel_flo            = 2.0  # Hz
> hi_accel_numharm        = 8    # max harmonics
> hi_accel_sigma          = 3.0  # threshold gaussian significance
> hi_accel_zmax           = 50   # bins
> hi_accel_flo            = 1.0  # Hz
> low_T_to_search         = 20.0 # sec
15d46
< 			
60a92
> 
71,72c103,104
<    bts = numpy.zeros(nn, dtype=numpy.float64)
<    vel = numpy.zeros(nn, dtype=numpy.float64)
---
>    bts = np.zeros(nn, dtype=np.float64)
>    vel = np.zeros(nn, dtype=np.float64)
74c106
<    avgvel = numpy.add.reduce(vel)/nn
---
>    avgvel = np.add.reduce(vel)/nn
77,112d108
< def fix_fil_posn(fil_filenm, hdrlen, ra, dec):
<     """
<     fix_fil_posn(fil_filenm, hdrlen, ra, dec):
<         Modify the filterbank header and update the RA and DEC
<             fields using the values given as input.  ra and dec
<             should be in 'HH:MM:SS.SSSS' and 'DD:MM:SS.SSSS' format.
<             hdrlen is the length of the filterbank header as
<             reported by PRESTO's 'readfile' or SIGPROC's 'header'.
<     """
<     newra = float(ra.replace(":", ""))
<     newdec = float(dec.replace(":", ""))
<     header = open(fil_filenm).read(hdrlen)
<     ra_ptr = header.find("src_raj")+len("src_raj")
<     dec_ptr = header.find("src_dej")+len("src_dej")
<     filfile = open(fil_filenm, 'rb+')
<     filfile.seek(ra_ptr)
<     filfile.write(struct.pack('d', newra))
<     filfile.seek(dec_ptr)
<     filfile.write(struct.pack('d', newdec))
<     filfile.close()
< 
< def read_db_posn(orig_filenm, beam):
<     """
<     read_db_posn(orig_filenm, beam):
<         Find the original WAPP filename in the db_pointing_file
<            and return the sexagesimal position strings for
<            the choen beam in that file.  Return None if not found.
<     """
<     offset = beam % 2
<     for line in open(db_pointing_file):
<         sline = line.split()
<         if sline[0].strip() == orig_filenm:
<             ra_str = sline[2*offset+1].strip()
<             dec_str = sline[2*offset+2].strip()
<             return ra_str, dec_str
<     return None
126a123
> 
136c133
<     subdmlist = numpy.asarray(subdmlist)
---
>     subdmlist = np.asarray(subdmlist)
138a136
> 
145c143
<     subdm = subdms[numpy.fabs(subdms - DM).argmin()]
---
>     subdm = subdms[np.fabs(subdms - DM).argmin()]
148c146,147
< def timed_execute(cmd): 
---
> 
> def timed_execute(cmd, stdout=None, stderr=subprocess.STDOUT): 
150c149
<     timed_execute(cmd):
---
>     timed_execute(cmd, stdout=None, stderr=subprocess.STDOUT):
153a153,157
> 
>             Output standard output to 'stdout' and standard
>             error to 'stderr'. Both are strings containing filenames.
>             If values are None, the out/err streams are not recorded.
>             By default stdout is None and stderr is combined with stdout.
154a159
>     # Log command to stdout
156a162,172
> 
>     stdoutfile = False
>     stderrfile = False
>     if type(stdout) == types.StringType:
>         stdout = open(stdout, 'w')
>         stdoutfile = True
>     if type(stderr) == types.StringType:
>         stderr = open(stderr, 'w')
>         stderrfile = True
>     
>     # Run (and time) the command. Check for errors.
158c174,183
<     os.system(cmd)
---
>     retcode = subprocess.call(cmd, shell=True, stdout=stdout, stderr=stderr)
>     if retcode < 0:
>         raise PrestoError("Execution of command (%s) terminated by signal (%s)!" % \
>                                 (cmd, -retcode))
>     elif retcode > 0:
>         raise PrestoError("Execution of command (%s) failed with status (%s)!" % \
>                                 (cmd, retcode))
>     else:
>         # Exit code is 0, which is "Success". Do nothing.
>         pass
159a185,190
>     
>     # Close file objects, if any
>     if stdoutfile:
>         stdout.close()
>     if stderrfile:
>         stderr.close()
161a193
> 
198a231
> 
201c234
<     class obs_info(fil_filenm)
---
>     class obs_info(filenms, resultsdir)
204,231c237,264
<     def __init__(self, fil_filenm):
<         self.fil_filenm = fil_filenm
<         self.basefilenm = fil_filenm.rstrip(".fil")
<         self.beam = int(self.basefilenm[-1])
<         for line in os.popen("readfile %s"%fil_filenm):
<             if "=" in line:
<                 key, val = line.split("=")
<                 if "Header" in key:
<                     self.hdrlen = int(val)
<                 if "Original" in key:
<                     split_orig_filenm = os.path.split(val.strip().strip("'"))[1].split(".")
<                     self.orig_filenm = ".".join(split_orig_filenm[0:-2] +
<                                                 split_orig_filenm[-1:])
<                 if "MJD" in key:
<                     self.MJD = float(val)
<                 if "RA" in key:
<                     val = val.strip()
<                     self.ra_string = val[:-9]+":"+val[-9:-7]+":"+val[-7:]
<                 if "DEC" in key:
<                     val = val.strip()
<                     self.dec_string = val[:-9]+":"+val[-9:-7]+":"+val[-7:]
<                 if "samples" in key:
<                     self.orig_N = int(val)
<                 if "T_samp" in key:
<                     self.dt = float(val) * 1e-6  # in sec
<                 if "Total Bandwidth" in key:
<                     self.BW = float(val)
<         self.orig_T = self.orig_N * self.dt
---
>     def __init__(self, filenms, resultsdir):
>         # Where to dump all the results
>         self.outputdir = resultsdir
>         
>         self.filenms = filenms
>         self.filenmstr = ' '.join(self.filenms)
>         self.basefilenm = os.path.split(filenms[0])[1].rstrip(".fits")
>         # Check that filenames have correct format
>         for filenm in self.filenms:
>             m = re.match(".*\.b(?P<beam>[0-7])s(?P<subband>[0-1])g[0-9]\..*\.fits", \
>                             filenm)
>             if m is None:
>                 raise ValueError("Data files don't appear to be ALFA MockSpec data " \
>                                     "(based on filename)!")
>         # m should be the re.match object from last filename 
>         # (Is this consistent with all files?)
>         self.alfabeam = int(m.group('beam'))
>         self.mocksubband = int(m.group('subband'))
>         
>         # Read info from PSRFITS file
>         spec_info = psrfits.SpectraInfo(filenms)
>         self.MJD = spec_info.start_MJD[0]
>         self.ra_string = spec_info.ra_str
>         self.dec_string = spec_info.dec_str
>         self.orig_N = spec_info.N
>         self.dt = spec_info.dt # in sec
>         self.BW = spec_info.BW
>         self.orig_T = spec_info.T
234,240d266
<         # Update the RA and DEC from the database file if required
<         newposn = read_db_posn(self.orig_filenm, self.beam)
<         if newposn is not None:
<             self.ra_string, self.dec_string = newposn
<             # ... and use them to update the filterbank file
<             fix_fil_posn(fil_filenm, self.hdrlen,
<                          self.ra_string, self.dec_string)
244,250d269
<         # Where to dump all the results
<         # Directory structure is under the base_output_directory
<         # according to base/MJD/filenmbase/beam
<         self.outputdir = os.path.join(base_output_directory,
<                                       str(int(self.MJD)),
<                                       self.basefilenm[:-2],
<                                       str(self.beam))
274c293,294
<         report_file.write("%s was processed on %s\n"%(self.fil_filenm, self.hostname))
---
>         report_file.write("Data (%s) were processed on %s\n" % \
>                                 (', '.join(self.filenms), self.hostname))
329c349
<                       numpy.arange(self.dmsperpass)*self.dmstep + lodm]
---
>                       np.arange(self.dmsperpass)*self.dmstep + lodm]
350c370
< def main(fil_filenm, workdir):
---
> def main(filenms, workdir, resultsdir):
355,356c375,376
<     # Get information on the observation and the jbo
<     job = obs_info(fil_filenm)
---
>     # Get information on the observation and the job
>     job = obs_info(filenms, resultsdir)
375c395
<     print "\nBeginning PALFA search of '%s'"%job.fil_filenm
---
>     print "\nBeginning PALFA search of %s" % (', '.join(job.filenms))
378,382c398,402
<     # rfifind the filterbank file
<     cmd = "rfifind -time %.17g -o %s %s > %s_rfifind.out"%\
<           (rfifind_chunk_time, job.basefilenm,
<            job.fil_filenm, job.basefilenm)
<     job.rfifind_time += timed_execute(cmd)
---
>     # rfifind the data file
>     cmd = "rfifind %s -time %.17g -o %s %s" % \
>           (datatype_flag, rfifind_chunk_time, job.basefilenm,
>            job.filenmstr)
>     job.rfifind_time += timed_execute(cmd, stdout="%s_rfifind.out" % job.basefilenm)
393c413
<         # Iterate over the individual passes through the .fil file
---
>         # Iterate over the individual passes through the data file
398,399c418,419
<             cmd = "prepsubband -sub -subdm %s -downsamp %d -nsub %d -mask %s -o subbands/%s %s > %s.subout"%\
<                   (ddplan.subdmlist[passnum], ddplan.sub_downsamp,
---
>             cmd = "prepsubband %s -sub -subdm %s -downsamp %d -nsub %d -mask %s -o subbands/%s %s"%\
>                   (datatype_flag, ddplan.subdmlist[passnum], ddplan.sub_downsamp,
401,402c421,422
<                    job.fil_filenm, subbasenm)
<             job.subbanding_time += timed_execute(cmd)
---
>                    job.filenmstr)
>             job.subbanding_time += timed_execute(cmd, stdout="%s.subout" % subbasenm)
405c425
<             cmd = "prepsubband -lodm %.2f -dmstep %.2f -numdms %d -downsamp %d -numout %d -o %s subbands/%s.sub[0-9]* > %s.prepout"%\
---
>             cmd = "prepsubband -lodm %.2f -dmstep %.2f -numdms %d -downsamp %d -numout %d -o %s subbands/%s.sub[0-9]*"%\
408,409c428,429
<                    job.basefilenm, subbasenm, subbasenm)
<             job.dedispersing_time += timed_execute(cmd)
---
>                    job.basefilenm, subbasenm)
>             job.dedispersing_time += timed_execute(cmd, stdout="%s.prepout" % subbasenm)
552c572,579
<     
---
>    
> 
> class PrestoError(Exception):
>     """Error to throw when a PRESTO program returns with 
>         a non-zero error code.
>     """
>     pass
> 
555,559c582,588
<     # sys.argv[1] = filterbank file name
<     # sys.argv[2] = working directory name
<     fil_filenm = sys.argv[1]
<     workdir = sys.argv[2]
<     main(fil_filenm, workdir)
---
>     # sys.argv[3:] = data file names
>     # sys.argv[1] = working directory name
>     # sys.argv[2] = results directory name
>     workdir = sys.argv[1]
>     resultsdir = sys.argv[2]
>     filenms = sys.argv[3:]
>     main(filenms, workdir, resultsdir)
